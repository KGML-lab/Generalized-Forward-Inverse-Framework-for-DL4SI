{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ff3304",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import openpyxl\n",
    "from openpyxl import Workbook\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torchvision.transforms import Compose\n",
    "from torch.utils.data import RandomSampler, DataLoader\n",
    "from torch.utils.data.dataloader import default_collate\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "from torch.nn.parallel import DistributedDataParallel\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from iunets import iUNet\n",
    "from dataset import FWIDataset\n",
    "# from networks import iunet_network\n",
    "from networks import forward_network, inverse_network, iunet_network, autoencoder\n",
    "\n",
    "import utils.transforms as T\n",
    "from utils.pytorch_ssim import *\n",
    "import utils.utilities as utils\n",
    "from utils.scheduler import WarmupMultiStepLR\n",
    "from utils.config_utils import get_config_name, get_latent_dim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c47759ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"OpenFWI arguments\")\n",
    "\n",
    "# Define command-line arguments\n",
    "parser.add_argument(\"--step\", type=int, default=0, help=\"Step value\")\n",
    "parser.add_argument(\"--file_size\", type=int, default=500, help=\"File size\")\n",
    "parser.add_argument(\"--vis_suffix\", action=\"store_true\", help=\"Enable visualization suffix\")\n",
    "parser.add_argument(\"--device\", default=\"cuda\", choices=[\"cpu\", \"cuda\"], help=\"Device (cpu or cuda)\")\n",
    "\n",
    "parser.add_argument(\"--k\", type=int, default=1, help=\"Value for k\")\n",
    "parser.add_argument(\"--workers\", type=int, default=4, help=\"Number of workers\")\n",
    "parser.add_argument(\"--lambda_g1v\", type=int, default=1, help=\"Value for lambda_g1v\")\n",
    "parser.add_argument(\"--lambda_g2v\", type=int, default=1, help=\"Value for lambda_g2v\")\n",
    "parser.add_argument(\"--batch_size\", type=int, default=50, help=\"Batch size\")\n",
    "parser.add_argument(\"--mask_factor\", type=float, default=0.0, help=\"Mask factor\")\n",
    "parser.add_argument(\"--sample_temporal\", type=int, default=1, help=\"Temporal sampling value\")\n",
    "parser.add_argument(\"--distributed\", action=\"store_true\", help=\"Enable distributed computing\")\n",
    "\n",
    "parser.add_argument(\"--num_images\", type=int, default=5, help=\"Number of images\")\n",
    "\n",
    "parser.add_argument(\"--model_type\", default=\"IUnetInverseModel\", help=\"Model type\")\n",
    "parser.add_argument(\"--base_path\", default=\"/projects/ml4science/OpenFWI/Results/SupervisedExperiment/\", help=\"Base path\")\n",
    "parser.add_argument(\"--model_save_name\", default=\"IUnetInverseModel\", help=\"Model save name\")\n",
    "parser.add_argument(\"--unet_depth\", type=int, default=2, help=\"UNet depth\")\n",
    "parser.add_argument(\"--unet_repeat_blocks\", type=int, default=2, help=\"Number of repeated UNet blocks\")\n",
    "\n",
    "parser.add_argument(\"--latent_dim\", type=int, default=70, help=\"Latent Dimension\")\n",
    "parser.add_argument(\"--skip\", type=int, default=1, help=\"Skip Connections for UNet\")\n",
    "parser.add_argument(\"--cfg_path\", default=\"../configs/\", help=\"Cfg path\")\n",
    "\n",
    "# Parse the command-line arguments\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "\n",
    "# Reinitialize variables without the 'args' prefix\n",
    "for key, value in vars(args).items():\n",
    "    exec(f\"{key} = value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb6eca2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_transform(data):\n",
    "    return torch.log10(1+torch.abs(data)) * torch.sign(data)\n",
    "\n",
    "def tanh_transform(data):\n",
    "    return torch.nn.functional.tanh(data)\n",
    "\n",
    "\n",
    "device = torch.device(device)\n",
    "\n",
    "datasets = [\"flatvel-a\", \"flatvel-b\",\n",
    "          \"curvevel-a\", \"curvevel-b\",\n",
    "          \"flatfault-a\", \"flatfault-b\",\n",
    "          \"curvefault-a\", \"curvefault-b\",\n",
    "          \"style-a\", \"style-b\"]\n",
    "\n",
    "model_names = ['FlatVel-A', 'FlatVel-B',\n",
    "          'CurveVel-A', 'CurveVel-B',\n",
    "         'FlatFault-A', 'FlatFault-B',\n",
    "         'CurveFault-A', 'CurveFault-B',\n",
    "         'Style-A', 'Style-B']\n",
    "\n",
    "datasets = [\"flatvel-a\", \"flatvel-b\"]\n",
    "\n",
    "model_names = ['FlatVel-A', 'FlatVel-B']\n",
    "\n",
    "# unet_repeat_blocks=1 \n",
    "# latent_dim=64\n",
    "# skip =0\n",
    "\n",
    "model_type = \"IUNET\"\n",
    "model_save_name= \"Invertible_XNet\"\n",
    "\n",
    "\n",
    "\n",
    "# #list of datasets on which model is evaluated\n",
    "# datasets = [\"flatvel-a\", \"flatvel-b\"]\n",
    "# #list of the datasets the model has been trained on\n",
    "# model_names = [\"FlatVel-A\", \"FlatVel-B\"] \n",
    "\n",
    "model_paths = []\n",
    "for model_name in model_names:\n",
    "    path_ = os.path.join(model_name, model_save_name, \"fcn_l1loss_ffb\")\n",
    "    model_paths.append(path_)\n",
    "    \n",
    "architecture_params = {\"UNetInverseModel_17M\":{\"unet_depth\": 2, \"unet_repeat_blocks\": 1}, \n",
    "                       \"UNetInverseModel_33M\":{\"unet_depth\": 2, \"unet_repeat_blocks\": 2},\n",
    "                       \"default\":{\"unet_depth\": unet_depth, \"unet_repeat_blocks\": unet_repeat_blocks}\n",
    "                      }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1724741",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterions = {\n",
    "    'MAE': lambda x, y: torch.mean(torch.abs(x - y)),\n",
    "    'MSE': lambda x, y: torch.mean((x - y) ** 2)\n",
    "}\n",
    "\n",
    "def get_dataset_path(dataset):\n",
    "    arr = dataset.split(\"-\")\n",
    "    base_path = f\"../train_test_splits/\"\n",
    "    \n",
    "    train_path = os.path.join(base_path, f\"{arr[0]}_{arr[1]}_train.txt\")\n",
    "    val_path = os.path.join(base_path, f\"{arr[0]}_{arr[1]}_val.txt\")\n",
    "    \n",
    "    return train_path, val_path\n",
    "\n",
    "def get_transforms(dataset, return_ctx=False):\n",
    "    f = open('../dataset_config.json')\n",
    "    ctx = json.load(f)[dataset]\n",
    "\n",
    "    transform_data = T.Normalize(ctx['data_mean'], ctx['data_std'])\n",
    "    transform_label = T.MinMaxNormalize(ctx['label_min'], ctx['label_max'])\n",
    "    if return_ctx:\n",
    "        return  transform_data, transform_label, ctx\n",
    "    return  transform_data, transform_label\n",
    "\n",
    "def get_dataloader(test_dataset, train_dataset=None):\n",
    "    if train_dataset is None:\n",
    "        train_dataset = test_dataset\n",
    "    \n",
    "    transform_data, transform_label, ctx = get_transforms(train_dataset, return_ctx=True)\n",
    "\n",
    "    train_anno, val_anno = get_dataset_path(test_dataset)\n",
    "        \n",
    "    print(f'Loading {test_dataset} validation data')\n",
    "    dataset_valid = FWIDataset(\n",
    "        val_anno,\n",
    "        preload=True,\n",
    "        sample_ratio=sample_temporal,\n",
    "        file_size=ctx['file_size'],\n",
    "        transform_data=transform_data,\n",
    "        transform_label=transform_label\n",
    "    )\n",
    "        \n",
    "    valid_sampler = RandomSampler(dataset_valid)\n",
    "\n",
    "    dataloader_valid = DataLoader(\n",
    "                                dataset_valid, batch_size=batch_size,\n",
    "                                sampler=valid_sampler, num_workers=workers,\n",
    "                                pin_memory=True, collate_fn=default_collate)\n",
    "    \n",
    "    print('Data loading over')\n",
    "        \n",
    "    return dataset_valid, dataloader_valid, transform_data, transform_label \n",
    "\n",
    "def evaluate(model, dataloader, transform_data, transform_label, k, criterions, device):   \n",
    "    \n",
    "    eval_metrics = {}\n",
    "    \n",
    "    vel_list, vel_pred_list= [], [] # store denormalized velocity predcition & gt in numpy \n",
    "    vel_norm_list, vel_pred_norm_list = [], [] # store normalized velocity prediction & gt in tensor\n",
    "\n",
    "    ssim_loss = SSIM(window_size=11)\n",
    "    ssim_value = 0\n",
    "    with torch.no_grad():\n",
    "        batch_idx = 0\n",
    "        for _, amp, vel in dataloader:\n",
    "            amp = amp.to(device)\n",
    "            vel = vel.to(device)\n",
    "            \n",
    "            vel_pred = model(amp)\n",
    "            \n",
    "            ssim_value += ssim_loss(vel / 2 + 0.5, vel_pred / 2 + 0.5).item()\n",
    "            \n",
    "            vel_np = transform_label.inverse_transform(vel.detach().cpu().numpy())\n",
    "            vel_list.append(torch.from_numpy(vel_np))\n",
    "            vel_norm_list.append(vel.detach().cpu())\n",
    "            \n",
    "            vel_pred_np = transform_label.inverse_transform(vel_pred.detach().cpu().numpy())\n",
    "            vel_pred_list.append(torch.from_numpy(vel_pred_np))\n",
    "            vel_pred_norm_list.append(vel_pred.detach().cpu())\n",
    "            \n",
    "            batch_idx += 1\n",
    "\n",
    "    vel, vel_pred = torch.cat(vel_list), torch.cat(vel_pred_list)\n",
    "    vel_norm, vel_pred_norm = torch.cat(vel_norm_list), torch.cat(vel_pred_norm_list)\n",
    "\n",
    "    for name, criterion in criterions.items():\n",
    "        \n",
    "        eval_metrics[f'Velocity_norm_{name}'] = criterion(vel_norm, vel_pred_norm).item()\n",
    "        eval_metrics[f'Velocity_unnorm_{name}'] = criterion(vel, vel_pred).item()\n",
    "        \n",
    "        \n",
    "    eval_metrics[f'Velocity_SSIM']  = ssim_value/len(dataloader) \n",
    "#     ssim_loss = SSIM(window_size=11)\n",
    "#     eval_metrics[f'Velocity_SSIM'] = ssim_loss(vel_norm / 2 + 0.5, vel_pred_norm / 2 + 0.5).item()\n",
    "    return eval_metrics\n",
    "\n",
    "def evaluate_iunet(model, dataloader, transform_data, transform_label, k, criterions, device):   \n",
    "    print(\"Evaluating IUNET models.\")\n",
    "    eval_metrics = {}\n",
    "    \n",
    "    vel_list, vel_pred_list= [], [] # store denormalized velocity predcition & gt in numpy \n",
    "    vel_norm_list, vel_pred_norm_list = [], [] # store normalized velocity prediction & gt in tensor\n",
    "\n",
    "    amp_list, amp_pred_list = [], []     # store denormalized waveform predcition & gt in numpy\n",
    "    amp_norm_list, amp_pred_norm_list = [], []  # store normalized waveform predcition & gt in numpy\n",
    "\n",
    "    ssim_loss = SSIM(window_size=11)\n",
    "    ssim_vel = 0\n",
    "    ssim_amp = 0\n",
    "    with torch.no_grad():\n",
    "        batch_idx = 0\n",
    "        for _, amp, vel in dataloader:\n",
    "            amp = amp.to(device)\n",
    "            vel = vel.to(device)\n",
    "            \n",
    "            vel_pred = model.inverse(amp)\n",
    "            amp_pred = model.forward(vel)\n",
    "            \n",
    "            ssim_vel += ssim_loss(vel / 2 + 0.5, vel_pred / 2 + 0.5).item()\n",
    "            ssim_amp += ssim_loss(amp / 2 + 0.5, amp_pred / 2 + 0.5).item()\n",
    "            \n",
    "            vel_np = transform_label.inverse_transform(vel.detach().cpu().numpy())\n",
    "            vel_list.append(torch.from_numpy(vel_np))\n",
    "            vel_norm_list.append(vel.detach().cpu())\n",
    "            \n",
    "            vel_pred_np = transform_label.inverse_transform(vel_pred.detach().cpu().numpy())\n",
    "            vel_pred_list.append(torch.from_numpy(vel_pred_np))\n",
    "            vel_pred_norm_list.append(vel_pred.detach().cpu())\n",
    "            \n",
    "            \n",
    "            amp_norm_list.append(amp.detach().cpu())\n",
    "            amp_pred_norm_list.append(amp_pred.detach().cpu())\n",
    "            \n",
    "            amp_np = transform_data.inverse_transform(amp.detach().cpu().numpy())\n",
    "            amp_pred_np = transform_data.inverse_transform(amp_pred.detach().cpu().numpy())\n",
    "            \n",
    "            amp_list.append(torch.from_numpy(amp_np))\n",
    "            amp_pred_list.append(torch.from_numpy(amp_pred_np))\n",
    "            \n",
    "            batch_idx += 1\n",
    "\n",
    "    vel, vel_pred = torch.cat(vel_list), torch.cat(vel_pred_list)\n",
    "    vel_norm, vel_pred_norm = torch.cat(vel_norm_list), torch.cat(vel_pred_norm_list)\n",
    "    \n",
    "    amp, amp_pred = torch.cat(amp_list), torch.cat(amp_pred_list)\n",
    "    amp_norm, amp_pred_norm = torch.cat(amp_norm_list), torch.cat(amp_pred_norm_list)\n",
    "    \n",
    "    amp_log, amp_pred_log = log_transform(amp), log_transform(amp_pred)\n",
    "    amp_tanh, amp_pred_tanh = tanh_transform(amp), tanh_transform(amp_pred)\n",
    "    \n",
    "    for name, criterion in criterions.items():\n",
    "        \n",
    "        eval_metrics[f'Velocity_norm_{name}'] = criterion(vel_norm, vel_pred_norm).item()\n",
    "        eval_metrics[f'Waveform_norm_{name}'] = criterion(amp_norm, amp_pred_norm).item()\n",
    "        \n",
    "        eval_metrics[f'Velocity_unnorm_{name}'] = criterion(vel, vel_pred).item()\n",
    "        eval_metrics[f'Waveform_unnorm_{name}'] = criterion(amp, amp_pred).item()\n",
    "        \n",
    "        eval_metrics[f'Waveform_unnorm_log_{name}'] = criterion(amp_log, amp_pred_log).item()\n",
    "        eval_metrics[f'Waveform_unnorm_tanh_{name}'] = criterion(amp_tanh, amp_pred_tanh).item()\n",
    "        \n",
    "        \n",
    "#     ssim_loss = SSIM(window_size=11)\n",
    "#     eval_metrics[f'Velocity_SSIM'] = ssim_loss(vel_norm / 2 + 0.5, vel_pred_norm / 2 + 0.5).item()\n",
    "#     eval_metrics[f'Waveform_SSIM'] = ssim_loss(amp_norm, amp_pred_norm).item()\n",
    "    \n",
    "    eval_metrics[f'Velocity_SSIM']  = ssim_vel/len(dataloader) \n",
    "    eval_metrics[f'Waveform_SSIM']  = ssim_amp/len(dataloader) \n",
    "    \n",
    "    return eval_metrics\n",
    "\n",
    "def set_inverse_params(inverse_model_params):\n",
    "        inverse_model_params.setdefault('IUnetInverseModel', {})\n",
    "        inverse_model_params['IUnetInverseModel']['cfg_path'] = cfg_path\n",
    "        inverse_model_params['IUnetInverseModel']['latent_dim'] = latent_dim\n",
    "        \n",
    "        inverse_model_params.setdefault('UNetInverseModel', {})\n",
    "        inverse_model_params['UNetInverseModel']['cfg_path'] = cfg_path\n",
    "        inverse_model_params['UNetInverseModel']['latent_dim'] = latent_dim\n",
    "        inverse_model_params['UNetInverseModel']['unet_depth'] = architecture_params[\"default\"][\"unet_depth\"]\n",
    "        inverse_model_params['UNetInverseModel']['unet_repeat_blocks'] = architecture_params[\"default\"][\"unet_repeat_blocks\"]\n",
    "        inverse_model_params['UNetInverseModel']['skip'] = skip # skip true\n",
    "        return inverse_model_params\n",
    "    \n",
    "def get_model(model_path, model_type):\n",
    "#     try:\n",
    "    print(model_path, model_type)\n",
    "    inverse_model_params = inverse_network.inverse_params\n",
    "    inverse_model_params = set_inverse_params(inverse_model_params)\n",
    "    model = inverse_network.model_dict[model_type](**inverse_model_params[model_type]).to(device)\n",
    "    checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(checkpoint['model'])\n",
    "#     except:\n",
    "#         print(\"Failed to load new model. Falling back to Legacy Code.\")\n",
    "#         inverse_model_params = inverse_network.inverse_params_legacy\n",
    "#         inverse_model_params['unet_depth'] = unet_depth\n",
    "#         inverse_model_params['unet_repeat_blocks'] = unet_repeat_blocks\n",
    "#         model_type = model_type+\"_Legacy\"\n",
    "#         model = inverse_network.model_dict[model_type](**inverse_model_params).to(device)\n",
    "#         checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "#         model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def get_model_iunet_(amp_model, vel_model, latent_channels, model_type):\n",
    "    if model_type == \"IUNET\":\n",
    "        iunet_model = iUNet(in_channels=latent_channels, dim=2, architecture=(4,4,4,4))\n",
    "        model = iunet_network.IUnetModel(amp_model, vel_model, iunet_model).to(device)\n",
    "        print(\"IUnet model initialized.\")\n",
    "    elif model_type == \"Decouple_IUnet\":\n",
    "        amp_iunet_model = iUNet(in_channels=latent_channels, dim=2, architecture=(4,4,4,4))\n",
    "        vel_iunet_model = iUNet(in_channels=latent_channels, dim=2, architecture=(4,4,4,4))\n",
    "        model = iunet_network.Decouple_IUnetModel(amp_model, vel_model, amp_iunet_model, vel_iunet_model).to(device)\n",
    "        print(\"Decoupled IUnetModel model initialized.\")\n",
    "    else:\n",
    "        print(f\"Invalid Model: {model_type}\")\n",
    "    return model\n",
    "\n",
    "def get_model_iunet(model_path, model_type):\n",
    "    try:   \n",
    "        print(model_path, model_type)\n",
    "        amp_cfg_name = get_config_name(latent_dim, model_type=\"amplitude\")\n",
    "        amp_model = autoencoder.AutoEncoder(cfg_path, amp_cfg_name).to(device)\n",
    "\n",
    "        # creating velocity cnn\n",
    "        vel_cfg_name = get_config_name(latent_dim, model_type=\"velocity\")\n",
    "        vel_model = autoencoder.AutoEncoder(cfg_path, vel_cfg_name).to(device)\n",
    "\n",
    "        latent_channels = get_latent_dim(cfg_path, amp_cfg_name)\n",
    "        model = get_model_iunet_(amp_model, vel_model, latent_channels, model_type)\n",
    "        checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "        \n",
    "    except:\n",
    "        print(\"Failed to load new model. Falling back to Legacy Code.\")\n",
    "        amp_input_channel = 5\n",
    "        amp_encoder_channel = [8, 16, 32, 64, 128]\n",
    "        amp_decoder_channel = [128, 64, 32, 16, 5]\n",
    "        amp_model = iunet_network.AmpAutoEncoder(amp_input_channel, amp_encoder_channel, amp_decoder_channel).to(device)\n",
    "\n",
    "        # creating velocity cnn\n",
    "        vel_input_channel = 1\n",
    "        vel_encoder_channel = [8, 16, 32, 64, 128]\n",
    "        vel_decoder_channel = [128, 64, 32, 16, 1]\n",
    "        vel_model = iunet_network.VelAutoEncoder(vel_input_channel, vel_encoder_channel, vel_decoder_channel).to(device)\n",
    "\n",
    "        latent_channels = 128\n",
    "        model = get_model_iunet_(amp_model, vel_model, latent_channels, model_type)\n",
    "        checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "        model.load_state_dict(checkpoint['model'])\n",
    "\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def generate_eval_matrix(model_names, model_paths, datasets):\n",
    "    \n",
    "    metrics = {}\n",
    "\n",
    "    for i in range(len(model_names)):\n",
    "        model_name = model_names[i]\n",
    "        model_path = os.path.join(base_path, model_paths[i], \"latest_checkpoint.pth\")\n",
    "        if not os.path.exists(model_path):\n",
    "            print(f\"The path does not exist: {model_path}\")\n",
    "            continue\n",
    "        if model_type == \"IUNET\":\n",
    "            model = get_model_iunet(model_path, model_type)\n",
    "        else:\n",
    "            model = get_model(model_path, model_type)\n",
    "        \n",
    "        vis_path = os.path.join(base_path, model_paths[i], 'Zero_Shot_Generalization')\n",
    "        if not os.path.exists(vis_path):\n",
    "            os.makedirs(vis_path)\n",
    "        \n",
    "        # We need the transform_data/transform_label for the trained model.\n",
    "        model_train_dataset = datasets[i]\n",
    "        \n",
    "        model_metrics = {}\n",
    "        for dataset in datasets:\n",
    "            dataset_val, dataloader_val,transform_data, transform_label= get_dataloader(test_dataset=dataset, train_dataset=model_train_dataset)\n",
    "            print(f'------------ Evaluating {dataset} ------------')\n",
    "            \n",
    "            if model_type == \"IUNET\":\n",
    "                eval_dict = evaluate_iunet(model, dataloader_val, transform_data, transform_label, k, criterions, device)\n",
    "            else:\n",
    "                eval_dict = evaluate(model, dataloader_val, transform_data, transform_label, k, criterions, device)\n",
    "            utils.plot_images(num_images, dataset_val, model, dataset, vis_path, device, transform_data, transform_label, plot=False, save_key=\"dataset\")\n",
    "            \n",
    "            for key in eval_dict.keys():\n",
    "                model_metrics.setdefault(key, []).append(eval_dict[key])\n",
    "                \n",
    "        metrics[model_name] = model_metrics\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def write_metrics(metrics_dict, filename):\n",
    "    \n",
    "    workbook = Workbook()\n",
    "    workbook.remove(workbook.active)\n",
    "    metrics_list = list(metrics_dict.values())[0].keys()\n",
    "    \n",
    "    for metric in metrics_list:\n",
    "        workbook.create_sheet(title=metric)\n",
    "        sheet = workbook[metric]\n",
    "        \n",
    "        for idx, dataset in enumerate(datasets, start=1):\n",
    "            cell = sheet.cell(row=1, column=idx+1, value=dataset)\n",
    "            cell.font = openpyxl.styles.Font(bold=True)\n",
    "            cell.alignment = openpyxl.styles.Alignment(horizontal='center')\n",
    "            \n",
    "        \n",
    "        for idx, model_name in enumerate(metrics_dict.keys(), start=1):\n",
    "            cell = sheet.cell(row=idx+1, column=1, value=model_name)\n",
    "            cell.alignment = openpyxl.styles.Alignment(horizontal='center')\n",
    "            \n",
    "            metric_values = metrics_dict[model_name][metric]\n",
    "            \n",
    "            for col, val in enumerate(metric_values, start=1):\n",
    "                cell = sheet.cell(row=idx+1, column=col+1, value=val)\n",
    "                cell.alignment = openpyxl.styles.Alignment(horizontal='center')\n",
    "    \n",
    "    workbook.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfb7ab0c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generate_eval_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m eval_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_eval_matrix\u001b[49m(model_names, model_paths, datasets)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generate_eval_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "eval_matrix = generate_eval_matrix(model_names, model_paths, datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4c7265fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_metrics(eval_matrix, f'eval_metric{model_save_name}.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92acb3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a6d471",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e70f022",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81014aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "openfwi_env",
   "language": "python",
   "name": "openfwi_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
